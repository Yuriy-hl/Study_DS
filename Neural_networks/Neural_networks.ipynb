{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b34dcba",
   "metadata": {},
   "source": [
    "## Персептрон (253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fd55db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theory.linear_algebra import Vector, dot\n",
    "\n",
    "# Ступенчатая функция\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_output(weights: Vector, bias: float, x: Vector) -> float:\n",
    "    \"\"\"Возвращает 1, если персептрон 'активируется', и 0, если нет\"\"\"\n",
    "    calculation = dot(weights, x) + bias\n",
    "    return step_function(calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b5765",
   "metadata": {},
   "source": [
    "### Логический вентиль И"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "116e257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "and_weights = [2., 2]\n",
    "and_bias = -3\n",
    "\n",
    "assert perceptron_output(and_weights, and_bias, [1, 1]) == 1\n",
    "assert perceptron_output(and_weights, and_bias, [0, 1]) == 0\n",
    "assert perceptron_output(and_weights, and_bias, [1, 0]) == 0\n",
    "assert perceptron_output(and_weights, and_bias, [0, 0]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cfe4e",
   "metadata": {},
   "source": [
    "### Логический вентиль ИЛИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6f31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_weights = [2., 2]\n",
    "or_bias = -1\n",
    "\n",
    "assert perceptron_output(or_weights, or_bias, [1, 1]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [0, 1]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [1, 0]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [0, 0]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488cd6d",
   "metadata": {},
   "source": [
    "### Логический вентиль НЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32e69a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_weights = [-2.]\n",
    "not_bias = 1\n",
    "\n",
    "assert perceptron_output(not_weights, not_bias, [0]) == 1\n",
    "assert perceptron_output(not_weights, not_bias, [1]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d1ae1",
   "metadata": {},
   "source": [
    "## Нейронные сети прямого распространения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfb533",
   "metadata": {},
   "source": [
    "### Сигмоидальная функция (step_function не подойдет, т.к. нам нужно дифф исчисление => нужна гладкая ф-я )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba092ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def sigmoid(t: float) -> float:\n",
    "    return 1 / (1 + math.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2c414",
   "metadata": {},
   "source": [
    "### Вычисляем выход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ca348",
   "metadata": {},
   "source": [
    "#### представим нейронную сеть как список (слоев) списков (нейронов) векторов(весов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbdee485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_output(weights: Vector, inputs: Vector) -> float:\n",
    "    # weights включает член смещения, inputs включает единицу\n",
    "    return sigmoid(dot(weights,inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e8a98",
   "metadata": {},
   "source": [
    "### Используем нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63cb23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def feed_forward(neural_network: List[List[Vector]],\n",
    "                 input_vector: Vector) -> List[Vector]:\n",
    "    \"\"\"Пропускает входной вектор через нейронную сеть.\n",
    "       Возвращает все слои (а не только последний)\"\"\"\n",
    "    outputs: List[Vector] = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1] # добавляем константу\n",
    "        output = [neuron_output(neuron, input_with_bias)    # Вычислить выход\n",
    "                  for neuron in layer]                      # для каждого нейрона.\n",
    "        outputs.append(output)                              # Сложить результаты\n",
    "\n",
    "        # Затем вход в следующий слой является выходом этого слоя\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a9536",
   "metadata": {},
   "source": [
    "### Логический вентиль исключающий ИЛИ (XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "348dcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_network = [# Скрытый слой\n",
    "              [[20., 20, -30],      # Нейрон 'И'\n",
    "               [20., 20, -10]],     # Нейрон 'ИЛИ'\n",
    "              # Выходной слой\n",
    "              [[-60., 60, -30]]]    # Нейрон '2-й вход, но не 1-й вход'\n",
    "\n",
    "# Функция feed_forward возвращает входы всех слоев, поэтому\n",
    "# [-1] получает окончательный выход и \n",
    "# [0] получает значение из результирующего вектора\n",
    "assert 0.000 < feed_forward(xor_network, [0, 0])[-1][0] < 0.001\n",
    "assert 0.999 < feed_forward(xor_network, [1, 0])[-1][0] < 1.000\n",
    "assert 0.999 < feed_forward(xor_network, [0, 1])[-1][0] < 1.001\n",
    "assert 0.000 < feed_forward(xor_network, [1, 1])[-1][0] < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ece49",
   "metadata": {},
   "source": [
    "## Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f417db2",
   "metadata": {},
   "source": [
    "### Ф-ия для вычисления градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dc7ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqerror_gradients(network: List[List[Vector]],\n",
    "                      input_vector: Vector,\n",
    "                      target_vector: Vector) -> List[List[Vector]]:\n",
    "    \"\"\"С учетом нейронной сети, вектора входов и вектора целей \n",
    "       сделать предсказание и вычислить градиент потери, т.е.\n",
    "       сумму квадратов ошибок по отношению к весам нейрона\"\"\"\n",
    "    # Прямое прохождение \n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # Градиенты по отношению к преактивационным выходам выходного нейрона\n",
    "    output_deltas = [output * (1 - output) * (output - target)\n",
    "                     for output, target in zip(outputs, target_vector)]\n",
    "    \n",
    "    # Градиенты по отношению к весам выходного нейрона\n",
    "    output_grads = [[output_deltas[i] * hidden_output\n",
    "                     for hidden_output in hidden_outputs + [1]]\n",
    "                    for i, output_neuron in enumerate(network[-1])]\n",
    "\n",
    "    # Градиенты по отношению к преактивационным выходам скрытого нейрона\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                         dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # Градиенты по отношению к весам скрытого нейрона\n",
    "    hidden_grads = [[hidden_deltas[i] * input for input in input_vector + [1]]\n",
    "                    for i, hidden_neuron in enumerate(network[0])]\n",
    "\n",
    "    return [hidden_grads, output_grads]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a06c8",
   "metadata": {},
   "source": [
    "### Генерируем тренировочные данные и инициализирем нашу нейронную сеть случайными весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d22877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "    \n",
    "# Тренировочные данные\n",
    "xs = [[0., 0], [0., 1], [1., 0], [1., 1]]\n",
    "ys = [[0.], [1.], [1.], [0.]]\n",
    "    \n",
    "# Начать со случайных весов\n",
    "network = [ # Скрытый слой: 2 выхода -> 2 выхода\n",
    "            [[random.random() for _ in range(2 + 1)],   # 1-й скрытый слой\n",
    "             [random.random() for _ in range(2 + 1)]],  # 2-й скрытый слой\n",
    "            # Выходной слой: 2 входа -> 1 выход\n",
    "            [[random.random() for _ in range(2 + 1)]]   # 1-й выхю нейрон\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc88c42",
   "metadata": {},
   "source": [
    "### Тренируем с помощью град спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8caf97",
   "metadata": {},
   "source": [
    "#### т.к у нас есть несколько векторов параметров, каждый со своим градиентом, а значит, нам придется вызвать ф-ю gradient_step для каждого из них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e44a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neural net for xor: 100%|██████████| 20000/20000 [00:00<00:00, 23030.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from gradient_descent import gradient_step\n",
    "import tqdm\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch in tqdm.trange(20000, desc=\"neural net for xor\"):\n",
    "        for x, y in zip(xs, ys):\n",
    "            gradients = sqerror_gradients(network, x, y)\n",
    "    \n",
    "            # Сделать градиентный шаг для каждого нейрона в каждом слое\n",
    "            network = [[gradient_step(neuron, grad, -learning_rate)\n",
    "                        for neuron, grad in zip(layer, layer_grad)]\n",
    "                       for layer, layer_grad in zip(network, gradients)]\n",
    "    \n",
    "# Проверить, что сеть усвоила XOR\n",
    "assert feed_forward(network, [0, 0])[-1][0] < 0.01\n",
    "assert feed_forward(network, [0, 1])[-1][0] > 0.99\n",
    "assert feed_forward(network, [1, 0])[-1][0] > 0.99\n",
    "assert feed_forward(network, [1, 1])[-1][0] < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367d748",
   "metadata": {},
   "source": [
    "## Задача Fizz Buzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956547d6",
   "metadata": {},
   "source": [
    "### Функция для генерирования векторов целей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99bfc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizz_buzz_encode(x: int) -> Vector:\n",
    "    if x % 15 == 0:\n",
    "        return [0, 0, 0, 1]\n",
    "    elif x % 5 == 0:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif x % 3 == 0:\n",
    "        return [0, 1, 0, 0]\n",
    "    else:\n",
    "        return [1, 0, 0, 0]\n",
    "    \n",
    "assert fizz_buzz_encode(2) == [1, 0, 0, 0]\n",
    "assert fizz_buzz_encode(6) == [0, 1, 0, 0]\n",
    "assert fizz_buzz_encode(10) == [0, 0, 1, 0]\n",
    "assert fizz_buzz_encode(30) == [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc6570",
   "metadata": {},
   "source": [
    "### Конвертируем числа в двоичные представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf0d0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(x: int) -> Vector:\n",
    "    binary: List[float] = []\n",
    "\n",
    "    for i in range(10):\n",
    "        binary.append(x % 2)\n",
    "        x = x // 2\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4af8a",
   "metadata": {},
   "source": [
    "### Тренировочный набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7fdf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [binary_encode(n) for n in range(101, 1024)]\n",
    "ys = [fizz_buzz_encode(n) for n in range(101, 1024)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df203865",
   "metadata": {},
   "source": [
    "### Создадим нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b422605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 25\n",
    "\n",
    "network = [\n",
    "    # Скрытый слой: 10 входов -> NUM_HIDDEN выходов\n",
    "    [[random.random() for _ in range(10 + 1)] for _ in range(NUM_HIDDEN)],\n",
    "\n",
    "    # Выходной слой: NUM_HIDDEN входов -> 4 выхода\n",
    "    [[random.random() for _ in range(NUM_HIDDEN + 1)] for _ in range(4)]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ccb02",
   "metadata": {},
   "source": [
    "### Тренируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f70128aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fizz buzz (loss: 16.22): 100%|██████████| 500/500 [01:32<00:00,  5.38it/s] \n"
     ]
    }
   ],
   "source": [
    "from theory.linear_algebra import squared_distance\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "with tqdm.trange(500) as t:\n",
    "        for epoch in t:\n",
    "            epoch_loss = 0.0\n",
    "    \n",
    "            for x, y in zip(xs, ys):\n",
    "                predicted = feed_forward(network, x)[-1]\n",
    "                epoch_loss += squared_distance(predicted, y)\n",
    "                gradients = sqerror_gradients(network, x, y)\n",
    "    \n",
    "                # Сделать градиентный шаг для каждого нейрона в каждом слое\n",
    "                network = [[gradient_step(neuron, grad, -learning_rate)\n",
    "                            for neuron, grad in zip(layer, layer_grad)]\n",
    "                        for layer, layer_grad in zip(network, gradients)]\n",
    "    \n",
    "            t.set_description(f\"fizz buzz (loss: {epoch_loss:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a9b14",
   "metadata": {},
   "source": [
    "### Наша сеть будет производить 4-мерный вектор, но нужно одно предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83166db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(xs: list) -> int:\n",
    "    \"\"\"Возвращает индекс наибольшего значения\"\"\"\n",
    "    return max(range(len(xs)), key=lambda i: xs[i])\n",
    "\n",
    "assert argmax([0, -1]) == 0\n",
    "assert argmax([-1, 0]) == 1\n",
    "assert argmax([-1, 10, 5, 20, -3]) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c9a3b",
   "metadata": {},
   "source": [
    "### Решение задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "914d3638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "2 2 2\n",
      "3 fizz fizz\n",
      "4 4 4\n",
      "5 5 buzz\n",
      "6 fizz fizz\n",
      "7 7 7\n",
      "8 8 8\n",
      "9 fizz fizz\n",
      "10 buzz buzz\n",
      "11 11 11\n",
      "12 fizz fizz\n",
      "13 13 13\n",
      "14 14 14\n",
      "15 fizzbuzz fizzbuzz\n",
      "16 16 16\n",
      "17 17 17\n",
      "18 fizz fizz\n",
      "19 19 19\n",
      "20 20 buzz\n",
      "21 fizz fizz\n",
      "22 22 22\n",
      "23 23 23\n",
      "24 fizz fizz\n",
      "25 buzz buzz\n",
      "26 26 26\n",
      "27 fizz fizz\n",
      "28 28 28\n",
      "29 29 29\n",
      "30 fizzbuzz fizzbuzz\n",
      "31 31 31\n",
      "32 32 32\n",
      "33 fizz fizz\n",
      "34 34 34\n",
      "35 buzz buzz\n",
      "36 fizz fizz\n",
      "37 37 37\n",
      "38 38 38\n",
      "39 fizz fizz\n",
      "40 buzz buzz\n",
      "41 41 41\n",
      "42 fizz fizz\n",
      "43 43 43\n",
      "44 44 44\n",
      "45 fizzbuzz fizzbuzz\n",
      "46 46 46\n",
      "47 47 47\n",
      "48 fizz fizz\n",
      "49 49 49\n",
      "50 buzz buzz\n",
      "51 fizz fizz\n",
      "52 52 52\n",
      "53 53 53\n",
      "54 fizz fizz\n",
      "55 buzz buzz\n",
      "56 56 56\n",
      "57 fizz fizz\n",
      "58 58 58\n",
      "59 59 59\n",
      "60 fizzbuzz fizzbuzz\n",
      "61 61 61\n",
      "62 62 62\n",
      "63 fizz fizz\n",
      "64 64 64\n",
      "65 65 buzz\n",
      "66 fizz fizz\n",
      "67 67 67\n",
      "68 68 68\n",
      "69 fizz fizz\n",
      "70 buzz buzz\n",
      "71 71 71\n",
      "72 fizz fizz\n",
      "73 73 73\n",
      "74 74 74\n",
      "75 fizzbuzz fizzbuzz\n",
      "76 76 76\n",
      "77 77 77\n",
      "78 fizz fizz\n",
      "79 79 79\n",
      "80 80 buzz\n",
      "81 fizz fizz\n",
      "82 82 82\n",
      "83 83 83\n",
      "84 fizz fizz\n",
      "85 buzz buzz\n",
      "86 86 86\n",
      "87 fizz fizz\n",
      "88 88 88\n",
      "89 89 89\n",
      "90 fizzbuzz fizzbuzz\n",
      "91 91 91\n",
      "92 92 92\n",
      "93 buzz fizz\n",
      "94 94 94\n",
      "95 buzz buzz\n",
      "96 fizz fizz\n",
      "97 97 97\n",
      "98 98 98\n",
      "99 fizz fizz\n",
      "100 buzz buzz\n",
      "95 / 100\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "    \n",
    "for n in range(1, 101):\n",
    "    x = binary_encode(n)\n",
    "    predicted = argmax(feed_forward(network, x)[-1])\n",
    "    actual = argmax(fizz_buzz_encode(n))\n",
    "    labels = [str(n), \"fizz\", \"buzz\", \"fizzbuzz\"]\n",
    "    print(n, labels[predicted], labels[actual])\n",
    "    \n",
    "    if predicted == actual:\n",
    "        num_correct += 1\n",
    "    \n",
    "print(num_correct, \"/\", 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
